# ğŸ›ï¸ Harvardâ€™s Artifacts Collection  
## ETL, SQL Analytics & Streamlit Application

---

## ğŸ“Œ Project Overview
This project is an end-to-end **ETL and data analytics application** built using the **Harvard Art Museums public API**.  
It enables users to dynamically collect museum artifact data, store it in a **MySQL (TiDB Cloud)** database, and explore the data using **SQL queries** through an interactive **Streamlit dashboard**.

---

## ğŸ¯ Objectives
- Build a complete ETL pipeline using real-world API data  
- Store structured cultural heritage data in a relational database  
- Enable SQL-based analysis and exploration through a web interface  

---

## ğŸ› ï¸ Technologies Used
- Python  
- Streamlit  
- SQLAlchemy  
- MySQL (TiDB Cloud)  
- Harvard Art Museums API  
- Pandas  

---

## ğŸ—‚ï¸ Project Architecture
```

Streamlit UI
â†“
Harvard Art Museums API
â†“
ETL (Extract â†’ Transform â†’ Load)
â†“
TiDB Cloud (MySQL Database)
â†“
SQL Analytics

````

---

## ğŸ—„ï¸ Database Design

### artifact_metadata
Stores general information about each artifact such as title, culture, period, century, classification, and acquisition details.

### artifact_media
Stores media-related information including image count, media count, and creation dates.

### artifact_colors
Stores aggregated color and hue information extracted from artifact images (one row per artifact).

---

## ğŸ”„ ETL Workflow
- **Extraction:** Fetches 2500 artifacts per user-selected classification from the API  
- **Transformation:** Cleans JSON data, handles null values, and normalizes nested structures  
- **Load:** Inserts data into MySQL using SQLAlchemy with duplicate prevention  

---

## ğŸ” SQL Analytics
- 20 predefined analytical queries   
- Join-based analysis across tables  
- All queries are executable directly from the Streamlit UI  

---

## ğŸ–¥ï¸ Streamlit Application Features
- Classification-based data collection  
- Live API data preview  
- One-click database insertion  
- Interactive SQL query execution  
- Tabular result display  

---

## ğŸš€ How to Run the Project

### 1 Install Dependencies
```bash
pip install -r requirements.txt
````
---

### 2 Run the Application

```bash
streamlit run app.py
```

---

## ğŸ“Š Expected Outcome

* Structured artifact data stored in a cloud database
* Ready-to-query SQL analytics environment
* Interactive dashboard for data exploration

---

## ğŸ‘¤ Author

**Rajkumar** - rajkbca498444@gmail.com
